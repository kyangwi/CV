{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyangwi/CV/blob/main/Face_Recognition_using_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lESkcwMKZd7Z",
        "outputId": "537e463c-573b-4e47-c853-22ba9d9c4724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NQGLAC0ZoWU",
        "outputId": "c001a739-6ca9-40cc-b07e-4cfd5e40e7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dlib-bin\n",
            "  Downloading dlib_bin-19.24.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Downloading dlib_bin-19.24.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m4.2/4.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dlib-bin\n",
            "Successfully installed dlib-bin-19.24.6\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.5)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.11.3)\n",
            "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface) (6.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface) (5.29.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.1.31)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1064781 sha256=a8719cf0ad4340433c69de8495584769709726aded6789ec0e5737b3a7eaf00e\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, insightface\n",
            "Successfully installed insightface-0.7.3 onnx-1.17.0\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.21.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dlib-bin\n",
        "!pip install numpy scikit-learn opencv-python\n",
        "!pip install insightface       # core library (ArcFace, RetinaFace models) :contentReference[oaicite:0]{index=0}\n",
        "!pip install onnxruntime-gpu   # GPU inference backend :contentReference[oaicite:1]{index=1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m6kKXI7paMpa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-YBm2M7bFDa",
        "outputId": "12c3d629-e4e4-40fc-8767-ccb34d4b4c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-28 18:15:28--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-04-28 18:15:28--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  31.8MB/s    in 1.9s    \n",
            "\n",
            "2025-04-28 18:15:30 (31.8 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnQchVhndOaz",
        "outputId": "5f7ee6a0-3c07-46dc-d64f-551c97e5f646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-28 18:15:36--  https://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21428389 (20M)\n",
            "Saving to: ‘dlib_face_recognition_resnet_model_v1.dat.bz2’\n",
            "\n",
            "dlib_face_recogniti 100%[===================>]  20.44M  16.8MB/s    in 1.2s    \n",
            "\n",
            "2025-04-28 18:15:37 (16.8 MB/s) - ‘dlib_face_recognition_resnet_model_v1.dat.bz2’ saved [21428389/21428389]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. USING dLib embeddings 128 vector**"
      ],
      "metadata": {
        "id": "QgZY7B8dxVxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2fl4QmFxbnq6"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/facedata\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oAe4ch8qc2VS"
      },
      "outputs": [],
      "source": [
        "import bz2\n",
        "comp = open(\"/content/shape_predictor_68_face_landmarks.dat.bz2\", \"rb\").read()\n",
        "with open(\"/content/drive/MyDrive/FaceRecognitionModels/shape_predictor_68_face_landmarks.dat\", \"wb\") as f:\n",
        "    f.write(bz2.decompress(comp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HjWvMUG5ePrs"
      },
      "outputs": [],
      "source": [
        "import bz2\n",
        "comp = open(\"/content/dlib_face_recognition_resnet_model_v1.dat.bz2\", \"rb\").read()\n",
        "with open(\"/content/drive/MyDrive/FaceRecognitionModels/dlib_face_recognition_resnet_model_v1.dat\", \"wb\") as f:\n",
        "    f.write(bz2.decompress(comp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0oucKAnjdB4C"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/drive/MyDrive/facedata\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BDMvpCAOaS9A"
      },
      "outputs": [],
      "source": [
        "# 1. Load models\n",
        "hog_detector = dlib.get_frontal_face_detector()\n",
        "shape_pred = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n",
        "face_rec = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P3XKEEZ_afCD"
      },
      "outputs": [],
      "source": [
        "# import tqdm\n",
        "# # 2. Prepare data\n",
        "# dataset_dir = image_path  # subfolders per person\n",
        "# embeddings, labels = [], []\n",
        "\n",
        "# for person in tqdm.tqdm(os.listdir(dataset_dir)):\n",
        "#     person_dir = os.path.join(dataset_dir, person)\n",
        "#     if not os.path.isdir(person_dir):\n",
        "#         continue\n",
        "#     for img_name in os.listdir(person_dir):\n",
        "#         img_path = os.path.join(person_dir, img_name)\n",
        "#         bgr = cv2.imread(img_path)\n",
        "#         if bgr is None:\n",
        "#             continue\n",
        "#         rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "#         # Detect faces\n",
        "#         rects = hog_detector(rgb, 1)  # upsample once\n",
        "#         if not rects:\n",
        "#             continue\n",
        "#         # Assume first detected face\n",
        "#         aligned = dlib.get_face_chip(rgb, shape_pred(rgb, rects[0]), size=150)\n",
        "#         # Compute embedding\n",
        "#         vec = np.array(face_rec.compute_face_descriptor(aligned, num_jitters=1))\n",
        "#         embeddings.append(vec)\n",
        "#         labels.append(person)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ksqiyYsxp5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.  Using ArcFace/Insightface/AntelopeV2**"
      ],
      "metadata": {
        "id": "dBnry7V9xqWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://sourceforge.net/projects/insightface.mirror/files/v0.7/antelopev2.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtPTHvUK_CcD",
        "outputId": "ca0e7909-9ab7-4e00-c03d-70fd9fa8f02e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-28 18:17:30--  https://sourceforge.net/projects/insightface.mirror/files/v0.7/antelopev2.zip\n",
            "Resolving sourceforge.net (sourceforge.net)... 104.18.12.149, 104.18.13.149, 2606:4700::6812:d95, ...\n",
            "Connecting to sourceforge.net (sourceforge.net)|104.18.12.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://sourceforge.net/projects/insightface.mirror/files/v0.7/antelopev2.zip/ [following]\n",
            "--2025-04-28 18:17:30--  https://sourceforge.net/projects/insightface.mirror/files/v0.7/antelopev2.zip/\n",
            "Reusing existing connection to sourceforge.net:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://sourceforge.net/projects/insightface.mirror/files/v0.7/antelopev2.zip/download [following]\n",
            "--2025-04-28 18:17:30--  https://sourceforge.net/projects/insightface.mirror/files/v0.7/antelopev2.zip/download\n",
            "Reusing existing connection to sourceforge.net:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://downloads.sourceforge.net/project/insightface.mirror/v0.7/antelopev2.zip?ts=gAAAAABoD8Y6JzmGA-rp_S-QIAW1ThaurUebN3fdyjhbCl_C0SuA-ksWcvfDl9FjrfwURuJkyx16kyzlfdvHXnQ6Niw5NM4s7g%3D%3D&use_mirror=versaweb&r= [following]\n",
            "--2025-04-28 18:17:30--  https://downloads.sourceforge.net/project/insightface.mirror/v0.7/antelopev2.zip?ts=gAAAAABoD8Y6JzmGA-rp_S-QIAW1ThaurUebN3fdyjhbCl_C0SuA-ksWcvfDl9FjrfwURuJkyx16kyzlfdvHXnQ6Niw5NM4s7g%3D%3D&use_mirror=versaweb&r=\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 104.18.12.149, 104.18.13.149, 2606:4700::6812:d95, ...\n",
            "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|104.18.12.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://versaweb.dl.sourceforge.net/project/insightface.mirror/v0.7/antelopev2.zip?viasf=1 [following]\n",
            "--2025-04-28 18:17:31--  https://versaweb.dl.sourceforge.net/project/insightface.mirror/v0.7/antelopev2.zip?viasf=1\n",
            "Resolving versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)... 162.251.232.173\n",
            "Connecting to versaweb.dl.sourceforge.net (versaweb.dl.sourceforge.net)|162.251.232.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 360662982 (344M) [application/octet-stream]\n",
            "Saving to: ‘antelopev2.zip’\n",
            "\n",
            "antelopev2.zip      100%[===================>] 343.95M  5.28MB/s    in 69s     \n",
            "\n",
            "2025-04-28 18:18:40 (4.96 MB/s) - ‘antelopev2.zip’ saved [360662982/360662982]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_file(zip_file_path, extract_to_path):\n",
        "    \"\"\"Unzips a zip file to a specified directory.\n",
        "\n",
        "    Args:\n",
        "        zip_file_path (str): The path to the zip file.\n",
        "        extract_to_path (str): The path to the directory where the contents\n",
        "                                 will be extracted.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to_path)\n",
        "        print(f\"Successfully extracted '{zip_file_path}' to '{extract_to_path}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Zip file not found at '{zip_file_path}'\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "zip_file = '/content/antelopev2.zip'  # Replace with the actual path to your zip file\n",
        "extract_dir = '/content/drive/MyDrive/FaceRecognitionModels' # Replace with the desired extraction directory\n",
        "\n",
        "# unzip_file(zip_file, extract_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_CYpE4VoMXf",
        "outputId": "46c5dd92-86dd-4d9e-dfd0-e4405c1cebd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted '/content/antelopev2.zip' to '/content/drive/MyDrive/FaceRecognitionModels'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/FaceRecognitionModels/antelopev2/detection\n",
        "!mkdir -p /content/drive/MyDrive/FaceRecognitionModels/antelopev2/recognition\n",
        "\n",
        "!mv /content/drive/MyDrive/FaceRecognitionModels/antelopev2/scrfd_10g_bnkps.onnx /content/drive/MyDrive/FaceRecognitionModels/antelopev2/detection/\n",
        "!mv /content/drive/MyDrive/FaceRecognitionModels/antelopev2/glintr100.onnx /content/drive/MyDrive/FaceRecognitionModels/antelopev2/recognition/\n"
      ],
      "metadata": {
        "id": "kQikkhriuLme"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from insightface.app import FaceAnalysis\n",
        "from insightface.model_zoo import model_zoo\n",
        "\n",
        "# 1. Manually load detection model\n",
        "det_model = model_zoo.get_model(\"/content/drive/MyDrive/FaceRecognitionModels/antelopev2/detection/scrfd_10g_bnkps.onnx\", task='detection')\n",
        "\n",
        "# 2. Manually load recognition model\n",
        "rec_model = model_zoo.get_model(\"/content/drive/MyDrive/FaceRecognitionModels/antelopev2/recognition/glintr100.onnx\", task='recognition')\n",
        "\n",
        "# 3. Now load FaceAnalysis\n",
        "app = FaceAnalysis()\n",
        "app.det_model = det_model\n",
        "app.rec_model = rec_model\n",
        "app.models = {'detection': det_model, 'recognition': rec_model}\n",
        "\n",
        "# 4. Prepare (ctx_id=0 means GPU, ctx_id=-1 means CPU)\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlruqe05vsWd",
        "outputId": "81781b01-04e6-4729-97f5-2671d1fa5d3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 281857/281857 [00:05<00:00, 52951.60KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 2. Prepare data with tqdm bars\n",
        "dataset_dir = image_path    # subfolders per person\n",
        "embeddings, labels = [], []\n",
        "\n",
        "for person in tqdm(os.listdir(dataset_dir), desc=\"Persons\", unit=\"person\"):\n",
        "    person_dir = os.path.join(dataset_dir, person)\n",
        "    if not os.path.isdir(person_dir):\n",
        "        continue\n",
        "\n",
        "    for img_name in tqdm(os.listdir(person_dir),\n",
        "                         desc=f\"Images ({person})\", unit=\"img\", leave=False):\n",
        "        img_path = os.path.join(person_dir, img_name)\n",
        "        bgr = cv2.imread(img_path)\n",
        "        if bgr is None:\n",
        "            continue\n",
        "\n",
        "        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "        # 3. Detect & align & embed in one go\n",
        "        faces = app.get(rgb)  # returns list of Face objects :contentReference[oaicite:5]{index=5}\n",
        "        if not faces:\n",
        "            continue\n",
        "\n",
        "        # 4. Take the first face\n",
        "        embedding = faces[0].embedding  # a 512-dim NumPy array :contentReference[oaicite:6]{index=6}\n",
        "        embeddings.append(embedding)\n",
        "        labels.append(person)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6k-d06V_RwV",
        "outputId": "e5722133-b797-4054-c0a1-8bf40d0a71da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Persons:   0%|          | 0/9 [00:00<?, ?person/s]\n",
            "Images (Meje):   0%|          | 0/8 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Meje):  12%|█▎        | 1/8 [00:01<00:09,  1.35s/img]\u001b[A\n",
            "Images (Meje):  25%|██▌       | 2/8 [00:02<00:06,  1.12s/img]\u001b[A\n",
            "Images (Meje):  38%|███▊      | 3/8 [00:03<00:05,  1.10s/img]\u001b[A\n",
            "Images (Meje):  50%|█████     | 4/8 [00:03<00:03,  1.18img/s]\u001b[A\n",
            "Images (Meje):  62%|██████▎   | 5/8 [00:04<00:02,  1.22img/s]\u001b[A\n",
            "Images (Meje):  75%|███████▌  | 6/8 [00:05<00:01,  1.42img/s]\u001b[A\n",
            "Images (Meje):  88%|████████▊ | 7/8 [00:05<00:00,  1.50img/s]\u001b[A\n",
            "Images (Meje): 100%|██████████| 8/8 [00:06<00:00,  1.33img/s]\u001b[A\n",
            "Persons:  11%|█         | 1/9 [00:06<00:54,  6.79s/person]\n",
            "Images (Patrick):   0%|          | 0/2 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Patrick):  50%|█████     | 1/2 [00:00<00:00,  1.21img/s]\u001b[A\n",
            "Images (Patrick): 100%|██████████| 2/2 [00:01<00:00,  1.04img/s]\u001b[A\n",
            "Persons:  22%|██▏       | 2/9 [00:08<00:27,  3.92s/person]\n",
            "Images (josh):   0%|          | 0/11 [00:00<?, ?img/s]\u001b[A\n",
            "Images (josh):   9%|▉         | 1/11 [00:00<00:04,  2.41img/s]\u001b[A\n",
            "Images (josh):  18%|█▊        | 2/11 [00:01<00:07,  1.28img/s]\u001b[A\n",
            "Images (josh):  27%|██▋       | 3/11 [00:02<00:08,  1.06s/img]\u001b[A\n",
            "Images (josh):  36%|███▋      | 4/11 [00:03<00:06,  1.01img/s]\u001b[A\n",
            "Images (josh):  45%|████▌     | 5/11 [00:04<00:04,  1.23img/s]\u001b[A\n",
            "Images (josh):  55%|█████▍    | 6/11 [00:05<00:05,  1.14s/img]\u001b[A\n",
            "Images (josh):  64%|██████▎   | 7/11 [00:07<00:04,  1.12s/img]\u001b[A\n",
            "Images (josh):  73%|███████▎  | 8/11 [00:08<00:03,  1.09s/img]\u001b[A\n",
            "Images (josh):  82%|████████▏ | 9/11 [00:08<00:02,  1.03s/img]\u001b[A\n",
            "Images (josh):  91%|█████████ | 10/11 [00:10<00:01,  1.09s/img]\u001b[A\n",
            "Images (josh): 100%|██████████| 11/11 [00:10<00:00,  1.04img/s]\u001b[A\n",
            "Persons:  33%|███▎      | 3/9 [00:19<00:42,  7.11s/person]\n",
            "Images (Richard):   0%|          | 0/13 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Richard):   8%|▊         | 1/13 [00:01<00:17,  1.48s/img]\u001b[A\n",
            "Images (Richard):  15%|█▌        | 2/13 [00:02<00:12,  1.13s/img]\u001b[A\n",
            "Images (Richard):  23%|██▎       | 3/13 [00:03<00:10,  1.08s/img]\u001b[A\n",
            "Images (Richard):  31%|███       | 4/13 [00:04<00:09,  1.05s/img]\u001b[A\n",
            "Images (Richard):  38%|███▊      | 5/13 [00:05<00:08,  1.12s/img]\u001b[A\n",
            "Images (Richard):  46%|████▌     | 6/13 [00:06<00:06,  1.11img/s]\u001b[A\n",
            "Images (Richard):  54%|█████▍    | 7/13 [00:06<00:04,  1.34img/s]\u001b[A\n",
            "Images (Richard):  62%|██████▏   | 8/13 [00:06<00:03,  1.60img/s]\u001b[A\n",
            "Images (Richard):  69%|██████▉   | 9/13 [00:07<00:02,  1.85img/s]\u001b[A\n",
            "Images (Richard):  77%|███████▋  | 10/13 [00:07<00:01,  1.88img/s]\u001b[A\n",
            "Images (Richard):  85%|████████▍ | 11/13 [00:08<00:00,  2.11img/s]\u001b[A\n",
            "Images (Richard):  92%|█████████▏| 12/13 [00:08<00:00,  2.06img/s]\u001b[A\n",
            "Images (Richard): 100%|██████████| 13/13 [00:09<00:00,  1.64img/s]\u001b[A\n",
            "Persons:  44%|████▍     | 4/9 [00:29<00:40,  8.06s/person]\n",
            "Images (Elyse):   0%|          | 0/14 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Elyse):   7%|▋         | 1/14 [00:00<00:05,  2.37img/s]\u001b[A\n",
            "Images (Elyse):  14%|█▍        | 2/14 [00:00<00:05,  2.39img/s]\u001b[A\n",
            "Images (Elyse):  21%|██▏       | 3/14 [00:01<00:06,  1.65img/s]\u001b[A\n",
            "Images (Elyse):  29%|██▊       | 4/14 [00:02<00:05,  1.93img/s]\u001b[A\n",
            "Images (Elyse):  36%|███▌      | 5/14 [00:02<00:04,  1.90img/s]\u001b[A\n",
            "Images (Elyse):  43%|████▎     | 6/14 [00:02<00:03,  2.09img/s]\u001b[A\n",
            "Images (Elyse):  50%|█████     | 7/14 [00:03<00:03,  2.21img/s]\u001b[A\n",
            "Images (Elyse):  57%|█████▋    | 8/14 [00:03<00:02,  2.17img/s]\u001b[A\n",
            "Images (Elyse):  64%|██████▍   | 9/14 [00:04<00:02,  2.05img/s]\u001b[A\n",
            "Images (Elyse):  71%|███████▏  | 10/14 [00:04<00:01,  2.21img/s]\u001b[A\n",
            "Images (Elyse):  79%|███████▊  | 11/14 [00:05<00:01,  2.15img/s]\u001b[A\n",
            "Images (Elyse):  86%|████████▌ | 12/14 [00:06<00:01,  1.50img/s]\u001b[A\n",
            "Images (Elyse):  93%|█████████▎| 13/14 [00:07<00:00,  1.30img/s]\u001b[A\n",
            "Images (Elyse): 100%|██████████| 14/14 [00:08<00:00,  1.19img/s]\u001b[A\n",
            "Persons:  56%|█████▌    | 5/9 [00:37<00:32,  8.18s/person]\n",
            "Images (Joviah):   0%|          | 0/6 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Joviah):  17%|█▋        | 1/6 [00:00<00:02,  2.19img/s]\u001b[A\n",
            "Images (Joviah):  33%|███▎      | 2/6 [00:00<00:01,  2.04img/s]\u001b[A\n",
            "Images (Joviah):  50%|█████     | 3/6 [00:01<00:01,  1.85img/s]\u001b[A\n",
            "Images (Joviah):  67%|██████▋   | 4/6 [00:02<00:01,  1.90img/s]\u001b[A\n",
            "Images (Joviah):  83%|████████▎ | 5/6 [00:02<00:00,  2.08img/s]\u001b[A\n",
            "Images (Joviah): 100%|██████████| 6/6 [00:02<00:00,  2.05img/s]\u001b[A\n",
            "Persons:  67%|██████▋   | 6/9 [00:40<00:19,  6.42s/person]\n",
            "Images (Gringo):   0%|          | 0/4 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Gringo):  25%|██▌       | 1/4 [00:00<00:01,  2.36img/s]\u001b[A\n",
            "Images (Gringo):  50%|█████     | 2/4 [00:00<00:00,  2.45img/s]\u001b[A\n",
            "Images (Gringo):  75%|███████▌  | 3/4 [00:01<00:00,  2.43img/s]\u001b[A\n",
            "Images (Gringo): 100%|██████████| 4/4 [00:01<00:00,  2.33img/s]\u001b[A\n",
            "Persons:  78%|███████▊  | 7/9 [00:42<00:09,  4.88s/person]\n",
            "Images (Jibu):   0%|          | 0/4 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Jibu):  25%|██▌       | 1/4 [00:00<00:01,  2.41img/s]\u001b[A\n",
            "Images (Jibu):  50%|█████     | 2/4 [00:00<00:00,  2.33img/s]\u001b[A\n",
            "Images (Jibu):  75%|███████▌  | 3/4 [00:01<00:00,  2.24img/s]\u001b[A\n",
            "Images (Jibu): 100%|██████████| 4/4 [00:01<00:00,  2.20img/s]\u001b[A\n",
            "Persons:  89%|████████▉ | 8/9 [00:44<00:03,  3.90s/person]\n",
            "Images (Don):   0%|          | 0/4 [00:00<?, ?img/s]\u001b[A\n",
            "Images (Don):  25%|██▌       | 1/4 [00:00<00:01,  2.11img/s]\u001b[A\n",
            "Images (Don):  50%|█████     | 2/4 [00:00<00:00,  2.27img/s]\u001b[A\n",
            "Images (Don):  75%|███████▌  | 3/4 [00:01<00:00,  2.48img/s]\u001b[A\n",
            "Images (Don): 100%|██████████| 4/4 [00:01<00:00,  2.38img/s]\u001b[A\n",
            "Persons: 100%|██████████| 9/9 [00:45<00:00,  5.08s/person]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**"
      ],
      "metadata": {
        "id": "ePIJ0_9kx85T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gCBYjlk_fwJL"
      },
      "outputs": [],
      "source": [
        "embeddings = np.array(embeddings)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame(embeddings)"
      ],
      "metadata": {
        "id": "XO0Q4cUWlENK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined = pd.concat([data,pd.Series(labels, name='label')],axis=1)"
      ],
      "metadata": {
        "id": "6mjMsNkblWGg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "combined = shuffle(combined).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "3dGtk3zmlwkx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined.head()"
      ],
      "metadata": {
        "id": "7Avf8qsTnYVv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0c219129-d518-4e1b-c2bb-8257859dc429"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.375179  1.729687  1.020849 -0.521455  0.238787  0.529591  0.051781   \n",
              "1 -0.931209 -1.557596 -1.295877 -0.854050 -1.310941 -1.506912  0.287071   \n",
              "2  0.088669  1.456016 -0.823273 -0.229758  0.532822 -0.100596  1.293430   \n",
              "3  0.752287 -0.493572 -1.920135  0.396108 -0.651088 -0.662359 -0.539687   \n",
              "4 -0.567595 -0.064378 -2.188199  1.203913 -0.517041 -0.169671 -0.952663   \n",
              "\n",
              "          7         8         9  ...       503       504       505       506  \\\n",
              "0  0.641301 -0.701668  0.951308  ...  0.144872 -0.450478  0.292580  0.100530   \n",
              "1  1.141141  0.710364  1.857338  ...  0.534868  0.437685  0.307075  0.511756   \n",
              "2  1.191461  1.056757 -1.089044  ...  1.977854  1.727073  0.896384  0.140648   \n",
              "3  0.103446  0.335007  1.066950  ... -1.608197 -0.524554 -0.275602 -0.217469   \n",
              "4 -0.651906 -1.417024  0.524723  ... -0.380877 -0.346660  0.083812 -0.347702   \n",
              "\n",
              "        507       508       509       510       511    label  \n",
              "0 -0.244754  1.572381  1.281895 -1.894132  0.393078   Gringo  \n",
              "1  1.645488  1.409317  0.600473 -0.794263 -1.330089  Richard  \n",
              "2 -0.031818  0.748293  0.453764 -0.130092  0.641524     josh  \n",
              "3  0.440505  0.658841 -0.793003  1.286612  4.167459    Elyse  \n",
              "4  1.001062 -0.736771  0.575759  1.238185  3.509979    Elyse  \n",
              "\n",
              "[5 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71eca5ac-76b4-46d2-9d9a-e4a70de9cebe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.375179</td>\n",
              "      <td>1.729687</td>\n",
              "      <td>1.020849</td>\n",
              "      <td>-0.521455</td>\n",
              "      <td>0.238787</td>\n",
              "      <td>0.529591</td>\n",
              "      <td>0.051781</td>\n",
              "      <td>0.641301</td>\n",
              "      <td>-0.701668</td>\n",
              "      <td>0.951308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.144872</td>\n",
              "      <td>-0.450478</td>\n",
              "      <td>0.292580</td>\n",
              "      <td>0.100530</td>\n",
              "      <td>-0.244754</td>\n",
              "      <td>1.572381</td>\n",
              "      <td>1.281895</td>\n",
              "      <td>-1.894132</td>\n",
              "      <td>0.393078</td>\n",
              "      <td>Gringo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.931209</td>\n",
              "      <td>-1.557596</td>\n",
              "      <td>-1.295877</td>\n",
              "      <td>-0.854050</td>\n",
              "      <td>-1.310941</td>\n",
              "      <td>-1.506912</td>\n",
              "      <td>0.287071</td>\n",
              "      <td>1.141141</td>\n",
              "      <td>0.710364</td>\n",
              "      <td>1.857338</td>\n",
              "      <td>...</td>\n",
              "      <td>0.534868</td>\n",
              "      <td>0.437685</td>\n",
              "      <td>0.307075</td>\n",
              "      <td>0.511756</td>\n",
              "      <td>1.645488</td>\n",
              "      <td>1.409317</td>\n",
              "      <td>0.600473</td>\n",
              "      <td>-0.794263</td>\n",
              "      <td>-1.330089</td>\n",
              "      <td>Richard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.088669</td>\n",
              "      <td>1.456016</td>\n",
              "      <td>-0.823273</td>\n",
              "      <td>-0.229758</td>\n",
              "      <td>0.532822</td>\n",
              "      <td>-0.100596</td>\n",
              "      <td>1.293430</td>\n",
              "      <td>1.191461</td>\n",
              "      <td>1.056757</td>\n",
              "      <td>-1.089044</td>\n",
              "      <td>...</td>\n",
              "      <td>1.977854</td>\n",
              "      <td>1.727073</td>\n",
              "      <td>0.896384</td>\n",
              "      <td>0.140648</td>\n",
              "      <td>-0.031818</td>\n",
              "      <td>0.748293</td>\n",
              "      <td>0.453764</td>\n",
              "      <td>-0.130092</td>\n",
              "      <td>0.641524</td>\n",
              "      <td>josh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.752287</td>\n",
              "      <td>-0.493572</td>\n",
              "      <td>-1.920135</td>\n",
              "      <td>0.396108</td>\n",
              "      <td>-0.651088</td>\n",
              "      <td>-0.662359</td>\n",
              "      <td>-0.539687</td>\n",
              "      <td>0.103446</td>\n",
              "      <td>0.335007</td>\n",
              "      <td>1.066950</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.608197</td>\n",
              "      <td>-0.524554</td>\n",
              "      <td>-0.275602</td>\n",
              "      <td>-0.217469</td>\n",
              "      <td>0.440505</td>\n",
              "      <td>0.658841</td>\n",
              "      <td>-0.793003</td>\n",
              "      <td>1.286612</td>\n",
              "      <td>4.167459</td>\n",
              "      <td>Elyse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.567595</td>\n",
              "      <td>-0.064378</td>\n",
              "      <td>-2.188199</td>\n",
              "      <td>1.203913</td>\n",
              "      <td>-0.517041</td>\n",
              "      <td>-0.169671</td>\n",
              "      <td>-0.952663</td>\n",
              "      <td>-0.651906</td>\n",
              "      <td>-1.417024</td>\n",
              "      <td>0.524723</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.380877</td>\n",
              "      <td>-0.346660</td>\n",
              "      <td>0.083812</td>\n",
              "      <td>-0.347702</td>\n",
              "      <td>1.001062</td>\n",
              "      <td>-0.736771</td>\n",
              "      <td>0.575759</td>\n",
              "      <td>1.238185</td>\n",
              "      <td>3.509979</td>\n",
              "      <td>Elyse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71eca5ac-76b4-46d2-9d9a-e4a70de9cebe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71eca5ac-76b4-46d2-9d9a-e4a70de9cebe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71eca5ac-76b4-46d2-9d9a-e4a70de9cebe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-69348163-74d6-4350-9cba-792eab8d3b90\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69348163-74d6-4350-9cba-792eab8d3b90')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-69348163-74d6-4350-9cba-792eab8d3b90 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Example target\n",
        "y = combined['label'].tolist()\n",
        "y\n",
        "\n",
        "# # Encode target\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "5mN3qLw6nc5W"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_encoded"
      ],
      "metadata": {
        "id": "SwsLgxP2oP1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27412da9-f374-446b-a30c-c1323e3d0f1b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 7, 8, 1, 1, 6, 5, 7, 1, 8, 4, 0, 2, 7, 3, 7, 3, 8, 1, 8, 4, 8,\n",
              "       1, 4, 7, 2, 4, 1, 0, 1, 7, 1, 7, 4, 7, 8, 3, 8, 7, 1, 0, 7, 0, 8,\n",
              "       7, 1, 3, 5, 5, 4, 7, 1, 7, 8, 2, 8, 5, 8, 1, 1, 6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "metadata": {
        "id": "eJUlvB5posOi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = tts((combined.drop('label', axis = 1)),y_encoded,test_size=0.13,random_state=6)"
      ],
      "metadata": {
        "id": "CqJaa7n9o78b"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "nhP5fIl6pKlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6447f550-6dfb-40f4-9ca3-dd06aeb19b32"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((53, 512), (9, 512), (53,), (9,))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(probability=True)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MQ9MZaLgqMxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c789f4c5-b87f-484a-9157-7f2d676004ff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "FE6HoVYTqcNb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "rGpQRMTBqmvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f8f204-488e-4f0f-994d-1f4a716a42bb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 7, 2, 6, 7, 4, 1, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "HZJu6Kleqn4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763e520c-ade6-41b0-e4b1-5367c3141285"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 7, 2, 6, 7, 4, 1, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "oaxPzIVJqtAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8112504f-5804-4e22-e364-cb231c6137a8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "fXqAai_zrhBj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(\n",
        "    iterations=100,     # number of trees\n",
        "    learning_rate=0.1,  # how fast to learn\n",
        "    depth=6,            # depth of trees\n",
        "    verbose=0           # set verbose>0 if you want training logs\n",
        ")"
      ],
      "metadata": {
        "id": "h_F-EZQprVyZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "GvDMeTsermll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0987891-39ac-4a41-acd1-f4ec2ac3110d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x78c1442f2e90>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test).flatten().tolist(),model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "EnMTWV1-rrEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a06d98b-112f-4a12-dc4b-c4ce9799c089"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([7, 7, 2, 6, 7, 4, 1, 8, 1],\n",
              " array([[0.07931066, 0.12526312, 0.07040454, 0.09613612, 0.0672763 ,\n",
              "         0.07732052, 0.06515198, 0.33482693, 0.08430984],\n",
              "        [0.0247456 , 0.02906472, 0.02278437, 0.02237649, 0.02429659,\n",
              "         0.0273301 , 0.02136271, 0.79396905, 0.03407037],\n",
              "        [0.09404578, 0.13721932, 0.23362142, 0.09813979, 0.10279342,\n",
              "         0.09515464, 0.08325608, 0.08788111, 0.06788844],\n",
              "        [0.08243591, 0.1116429 , 0.09766584, 0.0912031 , 0.0993461 ,\n",
              "         0.09958203, 0.2116115 , 0.08602306, 0.12048956],\n",
              "        [0.02127007, 0.02951138, 0.02061026, 0.02193555, 0.02096154,\n",
              "         0.02334719, 0.01813102, 0.82189394, 0.02233905],\n",
              "        [0.04360923, 0.05744025, 0.04674359, 0.04232024, 0.61778366,\n",
              "         0.04899882, 0.04235179, 0.05110941, 0.04964301],\n",
              "        [0.02696299, 0.76434037, 0.02665193, 0.02760887, 0.02358557,\n",
              "         0.02749897, 0.02598359, 0.04189588, 0.03547183],\n",
              "        [0.0248948 , 0.02628364, 0.02188911, 0.02237041, 0.02069215,\n",
              "         0.02449272, 0.02049717, 0.02695034, 0.81192967],\n",
              "        [0.03498636, 0.67658193, 0.0372438 , 0.03266834, 0.03099875,\n",
              "         0.04116709, 0.03199353, 0.04128387, 0.07307633]]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "KfPXtQhErxus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9055b92-011e-4a93-a429-58fac33c1702"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 7, 2, 6, 7, 4, 1, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from insightface.model_zoo import model_zoo\n",
        "from base64 import b64decode\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# ------------- 1) load clf + le --------------\n",
        "# with open('/content/drive/MyDrive/FaceRecognitionModels/face_rec_model_arcface.pkl','rb') as f:\n",
        "#     data = pickle.load(f)\n",
        "# clf = data['clf']\n",
        "# le  = data['le']\n",
        "\n",
        "# ------------- 2) setup InsightFace --------------\n",
        "app = FaceAnalysis()\n",
        "# (load your ONNX models exactly as you did before)\n",
        "det = model_zoo.get_model(\"/content/drive/MyDrive/FaceRecognitionModels/antelopev2/detection/scrfd_10g_bnkps.onnx\",\n",
        "                         task='detection')\n",
        "rec = model_zoo.get_model(\"/content/drive/MyDrive/FaceRecognitionModels/antelopev2/recognition/glintr100.onnx\",\n",
        "                         task='recognition')\n",
        "app.det_model = det\n",
        "app.rec_model = rec\n",
        "app.models = {'detection':det, 'recognition':rec}\n",
        "app.prepare(ctx_id=0, det_size=(640,640))\n",
        "\n",
        "# ----------- 3) capture photo util -------------\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "            async function takePhoto(quality) {\n",
        "              const div = document.createElement('div');\n",
        "              const capture = document.createElement('button');\n",
        "              capture.textContent = 'Capture';\n",
        "              div.appendChild(capture);\n",
        "\n",
        "              const video = document.createElement('video');\n",
        "              video.style.display = 'block';\n",
        "              const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "              document.body.appendChild(div);\n",
        "              div.appendChild(video);\n",
        "              video.srcObject = stream;\n",
        "              await video.play();\n",
        "\n",
        "              // Resize the output to fit the video element.\n",
        "              google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "              // Wait for Capture to be clicked.\n",
        "              await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "              const canvas = document.createElement('canvas');\n",
        "              canvas.width = video.videoWidth;\n",
        "              canvas.height = video.videoHeight;\n",
        "              canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "              stream.getVideoTracks()[0].stop();\n",
        "              div.remove();\n",
        "              return canvas.toDataURL('image/jpeg', quality);\n",
        "            }\n",
        "\n",
        "     ''')\n",
        "    display(js)\n",
        "    data = eval_js(f'takePhoto({quality})')\n",
        "    img_data = b64decode(data.split(',')[1])\n",
        "    with open(filename,'wb') as f: f.write(img_data)\n",
        "    return filename\n",
        "\n",
        "# ----------- 4) capture & read image -----------\n",
        "fname = take_photo()\n",
        "bgr = cv2.imread(fname)\n",
        "rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# ----------- 5) detect & embed face -----------\n",
        "faces = app.get(rgb)\n",
        "if not faces:\n",
        "    print(\"No face detected\")\n",
        "else:\n",
        "    emb = faces[0].embedding          # 512-D vector\n",
        "    # ----------- 6) predict & decode -----------\n",
        "    y_pred = clf.predict([emb])[0]    # integer, e.g. 2\n",
        "    name   = le.inverse_transform([y_pred])[0]\n",
        "    print(\"I see:\", name)\n"
      ],
      "metadata": {
        "id": "1RZDfmxbr3N5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "7f808411-fe5b-479d-a8a4-231f519f6775"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "set det-size: (640, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              " \n",
              "            async function takePhoto(quality) {\n",
              "              const div = document.createElement('div');\n",
              "              const capture = document.createElement('button');\n",
              "              capture.textContent = 'Capture';\n",
              "              div.appendChild(capture);\n",
              "\n",
              "              const video = document.createElement('video');\n",
              "              video.style.display = 'block';\n",
              "              const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "              document.body.appendChild(div);\n",
              "              div.appendChild(video);\n",
              "              video.srcObject = stream;\n",
              "              await video.play();\n",
              "\n",
              "              // Resize the output to fit the video element.\n",
              "              google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "              // Wait for Capture to be clicked.\n",
              "              await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "              const canvas = document.createElement('canvas');\n",
              "              canvas.width = video.videoWidth;\n",
              "              canvas.height = video.videoHeight;\n",
              "              canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "              stream.getVideoTracks()[0].stop();\n",
              "              div.remove();\n",
              "              return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "\n",
              "     "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I see: Richard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EtokK8DmtxI6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNDWgUhpjrsVbrWsuFHmWLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}